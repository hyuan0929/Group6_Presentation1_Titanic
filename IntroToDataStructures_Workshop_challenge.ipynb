{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Image Description](./images/RectangularVsNonRectangular.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Environment Setup\n",
        "---\n",
        "\n",
        "- Start by creating a Virtual Environment for your project\n",
        "\n",
        "Before running any code in this notebook, it's important to set up a clean Python environment to manage dependencies. We recommend using a **VENV-type virtual environment** in **Visual Studio Code (VSC)**. Follow these steps:\n",
        "\n",
        "### ‚úÖ Steps to Create a Virtual Environment in VSC\n",
        "\n",
        "1. **Open your project folder** in Visual Studio Code.\n",
        "\n",
        "2. **Open the terminal**:\n",
        "   - Go to `View` > `Terminal` or press `Ctrl + `` (backtick).\n",
        "\n",
        "3. **Create the virtual environment** by running:\n",
        "   ```bash\n",
        "   python -m venv venv\n",
        "   ```\n",
        "\n",
        "4. Once the environment is created, you need to **activate it** so that all Python packages you install are scoped to this project only.\n",
        "    On Windows:\n",
        "    ```bash\n",
        "    .\\venv\\Scripts\\activate\n",
        "    ```\n",
        "\n",
        "    On macOS/Linux\n",
        "    ```bash\n",
        "    source venv/bin/activate\n",
        "    ```\n",
        "\n",
        "5. ‚ö†Ô∏è Why Activation Matters\n",
        "Activating the virtual environment ensures that:\n",
        "\n",
        "- All package installations using pip are local to your project.\n",
        "- You avoid modifying the global Python environment, which could affect other projects or system tools.\n",
        "- Your project remains portable and reproducible, especially when sharing with others or deploying."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üì¶ Installing Required Libraries\n",
        "Once activated, install the required libraries using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install numpy pandas matplotlib\n",
        "pip install requests sympy ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Non-Rectangular Data Structures\n",
        "---\n",
        "\n",
        "- Data that does not fit into a traditional table format.\n",
        "- Examples include JSON, XML, hierarchical, and graph data structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Resources\n",
        "\n",
        "* Public APIs for Free (GitHub): https://github.com/public-apis/public-apis\n",
        "* Public APIs for Developers (RapidAPI): https://rapidapi.com/collection/list-of-free-apis\n",
        "* Free and Open Public APIs: https://mixedanalytics.com/blog/list-actually-free-open-no-auth-needed-apis/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetching JSON Data from an API Endpoint (Example 1)\n",
        "\n",
        "In this example, we will fetch JSON content from a free API endpoint using the `requests` library in Python. The API endpoint we are using is from JSONPlaceholder, which provides a simple REST API for testing and prototyping.\n",
        "\n",
        "1. **Import the `requests` library**: This library allows us to send HTTP requests in Python.\n",
        "2. **Define the API endpoint**: We specify the URL of the API endpoint we want to fetch data from.\n",
        "3. **Send a GET request**: We use the `requests.get()` method to send a GET request to the API endpoint.\n",
        "4. **Check if the request was successful**: We check the status code of the response to ensure the request was successful (status code 200).\n",
        "5. **Parse the JSON content**: If the request was successful, we use the `.json()` method to parse the JSON content of the response.\n",
        "6. **Display the JSON content**: Finally, we print the JSON content to the console.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define the API endpoint\n",
        "url = \"https://jsonplaceholder.typicode.com/posts/1\"\n",
        "\n",
        "# Send a GET request to the API endpoint\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON content\n",
        "    data = response.json()\n",
        "    # Display the JSON content\n",
        "    print(data)\n",
        "else:\n",
        "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetching JSON Data from an API Endpoint (Example 2)\n",
        "\n",
        "In this example, we will fetch JSON content from a free API endpoint using the `requests` library in Python. The API endpoint we are using is from the Dog CEO's Dog API, which provides random pictures of dogs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "David Espinosa\n",
        "PROG8431 \n",
        "Fall 2024\n",
        "Rectangular Data Structures\n",
        "\n",
        "Fetches a random dog image from the Dog CEO's Dog API.\n",
        "\"\"\"\n",
        "import requests\n",
        "\n",
        "def fetch_random_dog_image():\n",
        "    # URL of the JSON file from the Dog CEO's Dog API\n",
        "    url = 'https://dog.ceo/api/breeds/image/random'\n",
        "\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON content\n",
        "        data = response.json()\n",
        "        print(data)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
        "\n",
        "# Call the function\n",
        "fetch_random_dog_image()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetching JSON Data from an API Endpoint (Example 3)\n",
        "\n",
        "In this example, we will fetch JSON content from a free API endpoint using the `requests` library in Python. The API endpoint we are using is from the Represent API by Open North, which provides information about political representatives in Canada. This API is listed here:\n",
        "* https://github.com/public-apis/public-apis?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define the API endpoint\n",
        "url = \"https://represent.opennorth.ca/representatives/house-of-commons/\"\n",
        "\n",
        "# Define the headers\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
        "}\n",
        "\n",
        "# Send a GET request to the API endpoint with headers\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON content\n",
        "    data = response.json()\n",
        "    # Display the JSON content\n",
        "    print(data)\n",
        "else:\n",
        "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetching JSON Data from an API Endpoint (Example 4)\n",
        "\n",
        "In this example, we will fetch JSON content from a free API endpoint using the `requests` library in Python. The API endpoint we are using is from the Imgflip API, which provides a list of popular memes. This API is listed here: \n",
        "* https://mixedanalytics.com/blog/list-actually-free-open-no-auth-needed-apis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define the API endpoint\n",
        "url = \"https://api.imgflip.com/get_memes\"\n",
        "\n",
        "# Send a GET request to the API endpoint\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON content\n",
        "    data = response.json()\n",
        "    # Display the JSON content\n",
        "    print(data)\n",
        "else:\n",
        "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://i.imgflip.com/30b1gx.jpg\" width=\"400\" height=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge\n",
        "Running this API is not trivial, but offers many services, and it is federally funded (i.e. free):\n",
        "\n",
        "* https://api.weather.gc.ca/?lang=en\n",
        "* https://api.weather.gc.ca/openapi#/climate-hourly/getClimate-hourlyFeatures\n",
        "* https://eccc-msc.github.io/open-data/usage/use-case_arthur/use-case_arthur_en/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_climate_hourly_data():\n",
        "    base_url = \"https://api.weather.gc.ca\"\n",
        "    endpoint = \"/collections/climate-hourly/items\"\n",
        "    url = base_url + endpoint\n",
        "    \n",
        "    lat1, lng1 = 43.3500, -80.6000\n",
        "    lat2, lng2 = 43.5000, -80.3500\n",
        "    \n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=7)\n",
        "    date_range = f\"{start_date.strftime('%Y-%m-%d')}/{end_date.strftime('%Y-%m-%d')}\"\n",
        "\n",
        "    params = {\n",
        "        \"f\": \"json\",\n",
        "        \"bbox\": f\"{lng1},{lat1},{lng2},{lat2}\",\n",
        "        \"datetime\": date_range,\n",
        "        \"limit\": 100,\n",
        "        \"sortby\": \"+LOCAL_DATE\",  # Changed sorting property\n",
        "        \"properties\": \"TEMP, PRECIP_AMOUNT\"\n",
        "    }\n",
        "    \n",
        "    response = requests.get(url, params=params)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        \n",
        "        if 'features' in data and len(data['features']) > 0:\n",
        "            print(f\"Climate data for the Waterloo region ({lat1},{lng1} to {lat2},{lng2}):\")\n",
        "            print(f\"Time range: {start_date.date()} to {end_date.date()}\")\n",
        "            print(\"\\n\")\n",
        "            \n",
        "            for feature in data['features']:\n",
        "                props = feature['properties']\n",
        "                print(f\"Temperature: {props.get('TEMP', 'N/A')}¬∞C\")\n",
        "                print(f\"Total Precipitation: {props.get('PRECIP_AMOUNT', 'N/A')} mm\")\n",
        "                print(\"---\")\n",
        "        else:\n",
        "            print(\"No climate data available for the specified location and time range.\")\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "\n",
        "fetch_climate_hourly_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rectangular Data Structures\n",
        "---\n",
        "\n",
        "- Data arranged in rows and columns, often used in spreadsheets and databases.\n",
        "- Familiar formats include CSV files, SQL databases, etc.\n",
        "\n",
        "Sources:\n",
        "* Kaggle: https://www.kaggle.com/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading and Storing Data from a CSV File on the Internet (Example 1)\n",
        "\n",
        "In this example, we will read data from a CSV file available on the Internet and store it in a DataFrame using the `pandas` library in Python. The dataset we are using is the Titanic dataset, which contains information about the passengers on the Titanic.\n",
        "\n",
        "1. **Import the `pandas` library**: This library allows us to work with data in a tabular format.\n",
        "2. **Define the URL of the CSV file**: We specify the URL of the CSV file we want to fetch data from.\n",
        "3. **Read the CSV file from the URL**: We use the `pd.read_csv()` method to read the CSV file into a DataFrame.\n",
        "4. **Display the first few rows of the DataFrame**: We use the `.head()` method to display the first few rows of the DataFrame.\n",
        "5. **Save the DataFrame to a new CSV file**: We use the `.to_csv()` method to save the DataFrame to a new CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the URL of the CSV file\n",
        "csv_url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
        "\n",
        "# Read the CSV file from the URL into a DataFrame\n",
        "df = pd.read_csv(csv_url)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "df.to_csv(\"titanic_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading and Storing Data from a CSV File on the Internet (Example 2)\n",
        "\n",
        "In this example, we will read data from a CSV file available on the Internet and store it in a DataFrame using the `pandas` library in Python. The dataset we are using is the 126 Years of Historical Olympic Dataset, which contains information about the Olympic Games. The data source was obtained from: \n",
        "* https://www.kaggle.com/datasets/muhammadehsan02/126-years-of-historical-olympic-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the URL of the CSV file\n",
        "csv_url = \"https://raw.githubusercontent.com/rashida048/Datasets/master/olympics.csv\"\n",
        "\n",
        "# Read the CSV file from the URL into a DataFrame\n",
        "df = pd.read_csv(csv_url)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "df.to_csv(\"olympic_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Image Description](./images/CategoricalVsNumerical.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical vs. Numerical Variables\n",
        "\n",
        "1. **Categorical variables** represent categories or groups and are often non-numeric. In our dataset, 'Name' and 'Gender' are categorical variables.\n",
        "2. **Numerical variables** represent numeric values and can be either discrete or continuous. In our dataset, 'Age' and 'Salary' are numerical variables.\n",
        "\n",
        "In this example, we will demonstrate the difference between categorical and numerical variables using a sample dataset. \n",
        "The code below creates a sample dataset, separates the categorical and numerical variables, and displays them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 22],\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 55000]\n",
        "}\n",
        "\n",
        "# Convert the dataset into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Full Dataset:\")\n",
        "print(df)\n",
        "\n",
        "# Separate categorical and numerical variables\n",
        "categorical_vars = df.select_dtypes(include=['object'])\n",
        "numerical_vars = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# Display categorical variables\n",
        "print(\"\\nCategorical Variables:\")\n",
        "print(categorical_vars)\n",
        "\n",
        "# Display numerical variables\n",
        "print(\"\\nNumerical Variables:\")\n",
        "print(numerical_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Math, Calculus, and Trigonometry in Python\n",
        "\n",
        "In this example, we will demonstrate how to perform basic math, calculus, and trigonometry operations using Python. We will use the `math` library for basic math and trigonometry, and the `sympy` library for calculus.\n",
        "\n",
        "1. **Basic Math Operations**: Addition, subtraction, multiplication, division, and exponentiation.\n",
        "2. **Trigonometry**: Calculating sine, cosine, and tangent of an angle.\n",
        "3. **Calculus**: Differentiation and integration of functions.\n",
        "\n",
        "The code below demonstrates these operations.\n",
        "You can copy it into the Python command line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import sympy as sp\n",
        "\n",
        "# Basic Math Operations\n",
        "a = 10\n",
        "b = 5\n",
        "\n",
        "addition = a + b\n",
        "subtraction = a - b\n",
        "multiplication = a * b\n",
        "division = a / b\n",
        "exponentiation = a ** b\n",
        "\n",
        "print(\"Basic Math Operations:\")\n",
        "print(f\"Addition: {a} + {b} = {addition}\")\n",
        "print(f\"Subtraction: {a} - {b} = {subtraction}\")\n",
        "print(f\"Multiplication: {a} * {b} = {multiplication}\")\n",
        "print(f\"Division: {a} / {b} = {division}\")\n",
        "print(f\"Exponentiation: {a} ** {b} = {exponentiation}\")\n",
        "\n",
        "# Trigonometry\n",
        "angle = math.radians(45)  # Convert 45 degrees to radians\n",
        "\n",
        "sine = math.sin(angle)\n",
        "cosine = math.cos(angle)\n",
        "tangent = math.tan(angle)\n",
        "\n",
        "print(\"\\nTrigonometry:\")\n",
        "print(f\"Sine of 45 degrees: {sine}\")\n",
        "print(f\"Cosine of 45 degrees: {cosine}\")\n",
        "print(f\"Tangent of 45 degrees: {tangent}\")\n",
        "\n",
        "# Calculus\n",
        "x = sp.symbols('x')\n",
        "function = x**2 + 3*x + 2\n",
        "\n",
        "# Differentiation\n",
        "derivative = sp.diff(function, x)\n",
        "\n",
        "# Integration\n",
        "integral = sp.integrate(function, x)\n",
        "\n",
        "print(\"\\nCalculus:\")\n",
        "print(f\"Function: {function}\")\n",
        "print(f\"Derivative: {derivative}\")\n",
        "print(f\"Integral: {integral}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Image Description](./images/DataStructuresPython.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python Commands for Concatenation, Repetition, and Sequence Generation on Arrays\n",
        "\n",
        "In this example, we will demonstrate how to:\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **Concatenate elements or sub-vectors**:\n",
        "   - **Lists**: We use the `+` operator to concatenate `list1` and `list2`.\n",
        "   - **Arrays**: We use `np.concatenate()` to concatenate `array1` and `array2`.\n",
        "\n",
        "2. **Repeat elements or patterns**:\n",
        "   - **Lists**: We use the `*` operator to repeat `list1` three times.\n",
        "   - **Arrays**: We use `np.tile()` to repeat `array1` three times.\n",
        "\n",
        "3. **Generate sequences**:\n",
        "   - **Lists**: We use `range()` to generate a sequence of numbers from 1 to 10.\n",
        "   - **Arrays**: We use `np.arange()` to generate a sequence of numbers from 1 to 10.\n",
        "\n",
        "This example demonstrates how to perform these common operations in Python. If you have any more questions or need further assistance, feel free to ask!\n",
        "The code below demonstrates these operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Concatenate elements or sub-vectors\n",
        "list1 = [1, 2, 3]\n",
        "list2 = [4, 5, 6]\n",
        "concatenated_list = list1 + list2\n",
        "print(\"Concatenated List:\", concatenated_list)\n",
        "\n",
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([4, 5, 6])\n",
        "concatenated_array = np.concatenate((array1, array2))\n",
        "print(\"Concatenated Array:\", concatenated_array)\n",
        "\n",
        "# 2. Repeat elements or patterns\n",
        "repeated_list = list1 * 3\n",
        "print(\"Repeated List:\", repeated_list)\n",
        "\n",
        "repeated_array = np.tile(array1, 3)\n",
        "print(\"Repeated Array:\", repeated_array)\n",
        "\n",
        "# 3. Generate sequences\n",
        "sequence_list = list(range(1, 11))\n",
        "print(\"Sequence List:\", sequence_list)\n",
        "\n",
        "sequence_array = np.arange(1, 11)\n",
        "print(\"Sequence Array:\", sequence_array)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataFrames in Python\n",
        "\n",
        "In Python, a Data Frame is created with help of the `pandas` library. A `pandas` DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns).\n",
        "\n",
        "### Example\n",
        "\n",
        "The code below demonstrates how to create and manipulate a DataFrame in Python using `pandas`.\n",
        "\n",
        "* Creating a DataFrame: We create a dictionary with sample data and convert it into a DataFrame.\n",
        "* Displaying the DataFrame: We print the DataFrame to see its contents.\n",
        "* Accessing a specific column: We access the 'Age' column using `df['Age']`.\n",
        "* Filtering rows based on a condition: We filter rows where the 'Age' column is greater than 30.\n",
        "* Adding a new column: We add a new column 'Department' to the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 22],\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 55000]\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Accessing a specific column\n",
        "print(\"\\nAges:\")\n",
        "print(df['Age'])\n",
        "\n",
        "# Filtering rows based on a condition\n",
        "print(\"\\nRows where Age > 30:\")\n",
        "print(df[df['Age'] > 30])\n",
        "\n",
        "# Adding a new column\n",
        "df['Department'] = ['HR', 'Engineering', 'Marketing', 'Finance', 'HR']\n",
        "print(\"\\nDataFrame with new column:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 22],\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 55000]\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define a function to highlight rows based on a condition\n",
        "def highlight_age(row):\n",
        "    return ['background-color: blue' if row.Age > 30 else '' for _ in row]\n",
        "\n",
        "# Apply the styling\n",
        "styled_df = df.style.apply(highlight_age, axis=1)\\\n",
        "                    .set_table_styles([\n",
        "                        {'selector': 'thead th', 'props': [('background-color', 'lightblue'), ('color', 'black'), ('font-weight', 'bold')]},\n",
        "                        {'selector': 'tbody td', 'props': [('border', '1px solid black')]}\n",
        "                    ])\\\n",
        "                    .set_properties(**{'font-family': 'Arial', 'font-size': '14px'})\n",
        "\n",
        "# Display the styled DataFrame\n",
        "styled_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Image Description](./images/DataExploration.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"./data/Systolic1.csv\")\n",
        "\n",
        "# Preliminary inspection\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Calculate measures of central tendency\n",
        "mean_values = df.mean()\n",
        "median_values = df.median()\n",
        "mode_values = df.mode().iloc[0]  # mode() returns a DataFrame\n",
        "\n",
        "# Plotting with matplotlib\n",
        "labels = mean_values.index\n",
        "x = range(len(labels))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, mean_values.values, width=0.2, label='Mean', align='center')\n",
        "plt.bar([i + 0.2 for i in x], median_values.values, width=0.2, label='Median', align='center')\n",
        "plt.bar([i + 0.4 for i in x], mode_values.values, width=0.2, label='Mode', align='center')\n",
        "\n",
        "plt.xticks([i + 0.2 for i in x], labels)\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Measures of Central Tendency')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Dataset Overview: Systolic1.csv\n",
        "\n",
        "The dataset `Systolic1.csv` contains three columns labeled **X1**, **X2**, and **X3**, each representing numerical values that appear to be physiological measurements. While the column names are generic, we can begin exploring and interpreting their meaning based on typical ranges and relationships found in cardiovascular data.\n",
        "\n",
        "### üîç Initial Interpretations\n",
        "\n",
        "| Column | Sample Values | Possible Interpretation |\n",
        "|--------|----------------|--------------------------|\n",
        "| **X1** | 132, 143, 153, ... | Likely **Systolic Blood Pressure** (mmHg) |\n",
        "| **X2** | 52, 59, 67, ...    | Possibly **Diastolic Blood Pressure** (mmHg) |\n",
        "| **X3** | 173, 184, 194, ... | Could be **Heart Rate**, **Pulse Pressure**, or another derived cardiovascular metric |\n",
        "\n",
        "These interpretations are based on:\n",
        "\n",
        "- **Typical physiological ranges**:  \n",
        "  - Systolic pressure usually ranges from 90 to 140 mmHg in healthy adults, though higher values may occur.\n",
        "  - Diastolic pressure typically ranges from 60 to 90 mmHg.\n",
        "  - The values in **X3** are higher and may represent a derived metric such as **pulse pressure** (difference between systolic and diastolic), **cardiac output**, or **heart rate**.\n",
        "\n",
        "- **Data patterns**:  \n",
        "  The values in each column follow consistent patterns that align with known cardiovascular measurements, suggesting these are likely health-related metrics.\n",
        "\n",
        "### üß≠ Next Steps\n",
        "\n",
        "Further exploration could include:\n",
        "\n",
        "- Checking for correlations between the columns.\n",
        "- Comparing distributions and dispersion measures.\n",
        "- Validating interpretations with domain knowledge or metadata (if available).\n",
        "\n",
        "This initial analysis helps guide how we process and visualize the data in subsequent steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìå Central Tendency\n",
        "\n",
        "**Mean**, **Median**, **Mode**\n",
        "\n",
        "These are **measures of location** ‚Äî the first way of numerically identifying or characterizing a distribution or data set.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Summarizing Data\n",
        "\n",
        "- The **mean** is a measure of central tendency. It is what most people commonly refer to as the **‚Äúaverage.‚Äù**\n",
        "- The **median** is a measure of central tendency that divides a dataset into two equal halves.\n",
        "- The **mode** is a measure of central tendency that represents the **most frequently occurring value** in a dataset.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßÆ Mean: Mathematical Definition\n",
        "\n",
        "The **mean** (often called the \"average\") is a measure of central tendency defined mathematically as:\n",
        "\n",
        "$$\n",
        " \\mu = \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $\\mu$ is the **population mean**, the average of all the values in a **population**\n",
        "- $\\bar{x}$ is the **sample mean**, the average of all the values in a **sample**\n",
        "- $x_i$ are the individual data points\n",
        "- $n$ is the number of data points\n",
        "\n",
        "> ‚ö†Ô∏è **Important Concept**\n",
        "\n",
        "**The difference between a population and a sample is crucial in statistics**,  \n",
        "as it determines how data is **collected**, **analyzed**, and **interpreted**.\n",
        "\n",
        "\n",
        "### üìê How to Calculate the Mean\n",
        "\n",
        "To compute the mean:\n",
        "1. **Add up all the values** in the dataset.\n",
        "2. **Divide** the total by the **number of values**.\n",
        "\n",
        "#### Example:\n",
        "If your data points are:  \n",
        "45, 50, 55, 60, 65\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "\\text{Mean} = \\frac{45 + 50 + 55 + 60 + 65}{5} = \\frac{275}{5} = 55\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Challenge #1: Interpret the Mean\n",
        "\n",
        "Write a function called `interpret_mean` that uses the `df` DataFrame and calculates the **mean** of the `X2` attribute.\n",
        "\n",
        "üìå **Instructions**:\n",
        "- Define the function in the code cell below.\n",
        "- Use `df['X2'].mean()` to compute the mean.\n",
        "- After the function, call it using the appropriate parameters\n",
        "- Optionally, print or return the result with a short interpretation.\n",
        "\n",
        "#### üíª Write the code in the cell below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìã Mean Interpretation\n",
        "def interpret_mean(df):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üßÆ Median: Mathematical Definition\n",
        "\n",
        "- **50% of the samples are above the median**\n",
        "- **50% of the samples are below the median**\n",
        "\n",
        "This makes the median a useful indicator of the **center** of a distribution, especially when the data contains **outliers** or is **skewed**.\n",
        "\n",
        "\n",
        "### üìã Median Interpretation\n",
        "\n",
        "| Description                          | Interpretation                          |\n",
        "|--------------------------------------|------------------------------------------|\n",
        "| Median value                         | Middle value in an ordered dataset       |\n",
        "| If number of values is **odd**       | Median is the middle value               |\n",
        "| If number of values is **even**      | Median is the average of the two middle values |\n",
        "| Use case                             | Useful when data has outliers or is skewed |\n",
        "\n",
        "\n",
        "### üìä Example ‚Äî Median of 200-Meter Running Times\n",
        "\n",
        "### Rank Associated with Each Value\n",
        "\n",
        "| Rank | Time (in seconds) |\n",
        "|------|-------------------|\n",
        "| 1    | 24.1              |\n",
        "| 2    | 25.0              |\n",
        "| 3    | 25.2              |\n",
        "| 4    | 25.6              |\n",
        "| 5    | 25.7              |\n",
        "| 6    | 26.1              |\n",
        "| 7    | 27.8              |\n",
        "\n",
        "\n",
        "### üßÆ Median Calculation\n",
        "\n",
        "There are \\( n = 7 \\) data points, which is an **odd** number.\n",
        "\n",
        "To find the median, use the formula:\n",
        "\n",
        "$$\n",
        "\\text{Median position} = \\frac{n + 1}{2} = \\frac{7 + 1}{2} = 4\n",
        "$$\n",
        "\n",
        "So, the **median time** is the value at **Rank 4**, which is:\n",
        "\n",
        "**25.6 seconds**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Challenge #2: Interpret the Median\n",
        "\n",
        "Write a function called `interpret_median` that uses the `df` DataFrame and calculates the **median** of the `X2` attribute.\n",
        "\n",
        "üìå **Instructions**:\n",
        "- Define the function in the code cell below.\n",
        "- Use `df['X2'].median()` to compute the mean.\n",
        "- After the function, call it using the appropriate parameters\n",
        "- Optionally, print or return the result with a short interpretation.\n",
        "\n",
        "#### üíª Write the code in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìã Median Interpretation\n",
        "def interpret_median(df):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üß† Mode: Mathematical Definition\n",
        "\n",
        "- The mode is the value that appears **most often**.\n",
        "- It is useful for identifying **common patterns** or **popular categories** in data.\n",
        "\n",
        "\n",
        "### ü©∫ Example Use Case: Blood Type Distribution\n",
        "A hospital wants to ensure they have an adequate supply of different blood types for transfusions.  \n",
        "To do this, they need to know which blood type is **most common** among their patient population.\n",
        "\n",
        "#### Example Data:\n",
        "\n",
        "| Blood Type | Number of Patients |\n",
        "|------------|--------------------|\n",
        "| A          | 120                |\n",
        "| B          | 80                 |\n",
        "| AB         | 40                 |\n",
        "| O          | 160                |\n",
        "\n",
        "\n",
        "\n",
        "### ‚úÖ Mode Calculation\n",
        "\n",
        "- Blood Type O appears **160 times**\n",
        "- Blood Type A appears **120 times**\n",
        "- Blood Type B appears **80 times**\n",
        "- Blood Type AB appears **40 times**\n",
        "\n",
        "**ü©∏ The mode is Blood Type O**, as it is the most common blood type among the patients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Challenge #3: Interpret the Mode\n",
        "\n",
        "Write a function called `interpret_mode` that uses the `df` DataFrame and calculates the **mode** of the `X1` attribute.\n",
        "\n",
        "üìå **Instructions**:\n",
        "- Define the function in the code cell below.\n",
        "- Use `df['X2'].mode()` to compute the mean.\n",
        "- After the function, call it using the appropriate parameters\n",
        "- Optionally, print or return the result with a short interpretation.\n",
        "\n",
        "#### üíª Write the code in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìã Mode Interpretation\n",
        "def interpret_mode(df):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üìå Summary\n",
        "\n",
        "- The **mean** gives a central value that represents the dataset.\n",
        "- It is sensitive to **outliers**, which can skew the result.\n",
        "- Commonly used in both descriptive and inferential statistics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Challenge #4: Data Exploration\n",
        "\n",
        "Look at the Machine Learning Operations life cycle diagram below.\n",
        "\n",
        "![Image Description](./images/MachineLearningOperationsLifeCycle.png)\n",
        "\n",
        "Understand the **Product Initiation** and **Data Exploration** phases.\n",
        "Write code to read and load the `titanic data` data set into a Pandas-based data structure, `interpret_median`, understand the `meta data` and print the **initial exploration** like the top 5 rows and the `description`. Then make an interpretation of the data set and prepare a pitch about the use case. \n",
        "\n",
        "üìå **Instructions**:\n",
        "- Read and load the data set.\n",
        "- `Interpret` the data set, its attributes and their respective measures of `Central Tendency`.\n",
        "- Prepare a 50-word summary of the `Use Case` described by the `Data Set`\n",
        "\n",
        "#### üíª Write the summary in the cell below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚úÖ Challenge #4: Summary of the Use Case\n",
        "\n",
        "TODO - add the summary here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Challenge #5: Object-Oriented Python\n",
        "\n",
        "Re-use the code you write for challenges 1, 2 and 3, and the `interpret_mean`, `interpret_median`, and `interpret_mode` and make them **attributes** of a new class called `CentralTendency`and the `Titanic data set`.\n",
        "\n",
        "üìå **Instructions**:\n",
        "- Define the class in the code cell below.\n",
        "- Add a `constructor` and the three attributes to the class, each one with the proper parameters and return values.\n",
        "- After the class, instantiate an object of class `CentralTendency` called `stats`\n",
        "- Feed the data in the `df` data structure to the object, and have the code print the mean, median, and mode.\n",
        "\n",
        "#### üíª Write the code in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìã Central Tendency calculator\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (already done in previous cells)\n",
        "# df = pd.read_csv(\"Systolic1.csv\")\n",
        "\n",
        "# Define the CentralTendency class\n",
        "class CentralTendency:\n",
        "    def __init__(self, dataframe):\n",
        "        pass\n",
        "\n",
        "    def interpret_mean(self):\n",
        "        pass\n",
        "\n",
        "    def interpret_median(self):\n",
        "        pass\n",
        "\n",
        "    def interpret_mode(self):\n",
        "        pass\n",
        "\n",
        "# Instantiate the class\n",
        "# TODO \n",
        "\n",
        "# Print the results\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìå Measures of Dispersion\n",
        "\n",
        "**Range**, **Quartiles**, **Deviation**, **Variance**, **Standard Deviation**\n",
        "\n",
        "These are **measures of dispersion** ‚Äî second way of numerically identifying or characterizing a distribution or a set of data. How spread out, or tightly clustered, the data is.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Summarizing Data\n",
        "\n",
        "- The **range** is the difference between the **lowest** and **highest** values.\n",
        "- The **variance** of a set of numbers is the **average of the square of the deviations from the mean**.\n",
        "- The **standard deviation** of a set of numbers is the **positive square root of the variance**.\n",
        "- **Quartiles** divide a ranked dataset into **four equal parts**, each containing 25% of the data.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßÆ Range: Mathematical Definition\n",
        "\n",
        "The **range** is a measure of dispersion that describes the spread between the smallest and largest values in a dataset.\n",
        "\n",
        "### Formula:\n",
        "\n",
        "$$\n",
        "\\text{Range} = \\max(x) - \\min(x)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\max(x)$ is the maximum value in the dataset\n",
        "- $\\min(x)$ is the minimum value in the dataset\n",
        "\n",
        "\n",
        "### üìä Example ‚Äî Range of 200-Meter Running Times\n",
        "\n",
        "\n",
        "Given the dataset:\n",
        "\n",
        "$$\n",
        "x = \\{24.1,\\ 25.0,\\ 25.2,\\ 25.6,\\ 25.7,\\ 26.1,\\ 27.8\\}\n",
        "$$\n",
        "\n",
        "We compute:\n",
        "\n",
        "$$\n",
        "\\max(x) = 27.8,\\quad \\min(x) = 24.1\n",
        "$$\n",
        "\n",
        "So the range is:\n",
        "\n",
        "$$\n",
        "\\text{Range} = 27.8 - 24.1 = 3.7\n",
        "$$\n",
        "**‚úÖ The range of this dataset is 3.7 seconds.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Assumes df = pd.read_csv(\"Systolic1.csv\")\n",
        "\n",
        "# Define a function to interpret the range of the X2 column\n",
        "def interpret_range(dataframe):\n",
        "    min_val = dataframe['X2'].min()\n",
        "    max_val = dataframe['X2'].max()\n",
        "    range_val = max_val - min_val\n",
        "    return f\"The range of X2 is {range_val}, calculated as the difference between the maximum value ({max_val}) and the minimum value ({min_val}). This indicates the spread of the data.\"\n",
        "\n",
        "# Call the function and print the interpretation\n",
        "print(interpret_range(df))\n",
        "\n",
        "# TODO  - Implement the method to calculate and interpret the range by charting it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßÆ Variance: Mathematical Definition\n",
        "\n",
        "The **variance** of a set of numbers is the average of the square of the deviations from the mean.\n",
        "\n",
        "### Formula:\n",
        "\n",
        "For a dataset with \\( n \\) values \\( x_1, x_2, \\ldots, x_n \\), and mean \\( \\bar{x} \\), the **sample variance** is defined as:\n",
        "\n",
        "$$\n",
        "s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $s^2$ is the sample variance\n",
        "- $x_i$ are the individual data points\n",
        "- $\\bar{x}$ is the sample mean\n",
        "- $ n $ is the number of data points\n",
        "\n",
        "\n",
        "#### ‚úÖ Interpretation\n",
        "\n",
        "Variance quantifies how much the data points in a sample or population differ from the mean.  \n",
        "- A **higher variance** indicates more spread in the data\n",
        "- A **lower variance** suggests the data points are closer to the mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Assumes df = pd.read_csv(\"Systolic1.csv\")\n",
        "\n",
        "# Define a function to interpret the variance of the X2 column\n",
        "def interpret_variance(dataframe):\n",
        "    variance_val = dataframe['X2'].var()\n",
        "    return f\"The variance of X2 is {variance_val:.2f}. This value quantifies how much the X2 values deviate from their mean, indicating the spread of the data.\"\n",
        "\n",
        "# Call the function and print the interpretation\n",
        "print(interpret_variance(df))\n",
        "\n",
        "\n",
        "# TODO - Implement the method to calculate and interpret the variance by charting it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßÆ Standard Deviation: Mathematical Definition\n",
        "\n",
        "The **standard deviation** is the square root of the variance.  \n",
        "It measures how much the data values deviate from the mean on average.\n",
        "\n",
        "For a dataset with $n$ values $x_1, x_2, \\ldots, x_n$, and mean $\\bar{x}$, the **sample standard deviation** is:\n",
        "\n",
        "$$\n",
        "s = \\sqrt{ \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 }\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $s$ is the sample standard deviation\n",
        "- $x_i$ are the individual data points\n",
        "- $bar{x}$ is the sample mean\n",
        "- $n$ is the number of data points\n",
        "\n",
        "### üìå Interpretation\n",
        "\n",
        "It is another measure of the spread or dispersion of a set of data points. It quantifies the amount of variation or dispersion of a set of values. Like variance, it provides insight into how much the data deviates from the mean.\n",
        "\n",
        "- A **low standard deviation** means the data points are close to the mean.\n",
        "- A **high standard deviation** indicates the data is more spread out.\n",
        "- It is widely used in statistics to understand variability and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Assumes df = pd.read_csv(\"Systolic1.csv\")\n",
        "\n",
        "# Compute the standard deviation of the X2 column\n",
        "std_dev_x2 = df['X2'].std()\n",
        "\n",
        "# Print the result\n",
        "print(\"Standard Deviation of X2:\", std_dev_x2)\n",
        "\n",
        "# TODO - Implement the method to calculate and interpret the standard deviation by charting it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üßÆ Quartiles: Definitions\n",
        "\n",
        "**Quartiles** divide a ranked dataset into four equal parts, each containing 25% of the data.\n",
        "\n",
        "- **Q1 (First Quartile)**: 25% of the data falls below this value.\n",
        "- **Q2 (Second Quartile / Median)**: 50% of the data falls below this value.\n",
        "- **Q3 (Third Quartile)**: 75% of the data falls below this value.\n",
        "- **IQR (Interquartile Range)**: Difference between Q3 and Q1.\n",
        "\n",
        "$$\n",
        "\\text{IQR} = Q_3 - Q_1\n",
        "$$\n",
        "\n",
        "\n",
        "### üìå Interpretation\n",
        "\n",
        "- Quartiles help identify the **spread** and **skewness** of data.\n",
        "- The **IQR** is useful for detecting **outliers** and understanding variability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Assumes df = pd.read_csv(\"Systolic1.csv\")\n",
        "\n",
        "# Compute quartiles and IQR for the X2 column\n",
        "q1 = df['X2'].quantile(0.25)\n",
        "q2 = df['X2'].quantile(0.50)  # Median\n",
        "q3 = df['X2'].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Print the results\n",
        "print(\"First Quartile (Q1):\", q1)\n",
        "print(\"Second Quartile (Q2 / Median):\", q2)\n",
        "print(\"Third Quartile (Q3):\", q3)\n",
        "print(\"Interquartile Range (IQR):\", iqr)\n",
        "\n",
        "# TODO - Implement the method to calculate and interpret the standard deviation by charting it"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}